Seminar 1
Release planning is consistent of two different approaches seen as the art and the science sides of release planning  [1]. 
In this article the author presents a methodology of release planning based on algorithm with three different unknowns.  
The algorithm takes in to consideration features composed of requirements with high dependencies. Another part is effort prioritising and the last step is prioritising the stakeholders. 
Here the authors wanted to combine a scientific way of presenting decisions that can be confusing and complicated for the human mind to consider each separate. 
Each step is clearly described by the author and the article and the idea is easy to follow. The authors take in to consideration three factors that are usually at odds with each other. 
We might have interesting features but are either to costly or might be not needed or we might have a need and resources but the feature is unclear or confusing. 
By using this algorithm, we can present features with numerical worth based of the need, complexity and the resources needed to develop. Furthermore, the algorithm can suggest which release should include which feature. 
I can see use of this algorithm in the real world. We could involve real stakeholders where they can vote and afterwards we can insert the results of the votes in to our system. 
This will give us realistic presentation of what the stakeholders are interested in. Then we could present to the stakeholders the results so that we can reflect on them. The results can be used as leverage when conflict arise.
 
From my perspective the mathematical explanations are hard to understand. 
But regardless the explanations provided are easy to understand and the math becomes a little bit not important as long we understand the point that the author is trying to make. 
The author intends the tool to be used as a simulator of different stake holders and then the manager can use the tool to compare his idea to the result of the tool. 
I think that the intended use that the author presents this tool for is short sided. 
Because if you have the stakeholders then the tool can be used by the stakeholders so that they can get better understanding of the dynamic of cost regarding development of software. 
For example, if the stakeholder is not informed some features might be misunderstood as easy or cheap to develop. 
By using the tool, the stakeholder can easily understand why they are wrong when they see the connections and dependencies that that feature has with other features. 

Requirements engineering is affected and has an effect on other phases on the project[2]. 
Here the authors argue that there are many dependent variables regarding measuring of success of the project, requirements engineering project, and product. 
The author presents a way to classify dependencies in different categories. The categories presented in the article are society, project, product, company, and requirements phase. 
All these categories can be directly connected with the measurements of the success.

The article is convincing and claims made by it are backed up by articles. The subject matter is easy to understand and follow. I like the idea that success has different meanings when viewed from different perspectives. 
For an example the commercial success of one product might not be directly a success for the company if the company loses money from other projects that were affected by the development of that product. 
Another argument that I found interesting was regarding the improvement of the requirements engineering phase. When measuring improvements on small areas the impact that these improvements have on the whole needs to be considered. 
For an example decreasing the elicitation and documentation time might be improvement by itself but might have a negative effect on the project by whole. 
This might lead to unclear requirements and make validation and verification harder to perform and less reliable when performed.
 
The study presents problems that are obvious but not easy to notice or recognise if not aware of them. It is hard to find real issues with the paper without reviewing all of the presented references. 
However, there might be a bit of confirmation bias in a sense that the article is not a literature review but it is aimed at a specific subject with a lot of arguments to support its claims. 
The author chooses articles that support his claims only. However, this is not a big problem because the format of the article is such as that this validity threat is obvious and easy to forgive. 
Because of that some arguments might be considered incorrect in certain circumstances. We can take the previous example about the commercial success product. 
In that case if that product is the only product that the company owns and the company does not have other projects that can be affected by the product then the statement becomes incorrect. 
That is because the product can’t effect other projects in the way that we described. However, there is still other perspectives that we can take and make similar claim apply in a similar way. 
That is why this I think that this tread to validity is not a significant one. We can apply the teachings of the article and do mental gymnastics and still realise dependent variables where we did not see before. 

In an environment where we get constant feedback and requests from the stake holders the requirements need to be maintained continuously [3]. 
Here the authors present a method to do just that. The method is called RAM and the idea is to continuously work on requirements with different abstraction level. 
This means that the method is broken down in to two parts. The first one is the continuous creation and modification of the requirements and the second one is the reduction of the abstraction level. 

Capture or elicit is straight forward and it means to document the requirement. Reducing the abstraction level is a bit more complicated and RAM gives us a solution. 
The solution is to specify different abstraction levels and to categorise each requirement accordingly to those levels. The levels must be like climbing down stairs the lower we go the less abstract the requirements get. 
The amount of levels is dynamic and can be adjusted accordingly for the case needs. 
So the RAM method says capture a requirement, see if it fits the product and company strategy and if it does place the requirement on the right level of abstraction. 
If the abstraction level of that requirement is high, then we need to get it down to the lowest level so that the requirement can be used by developers.
 
RAM seems like an interesting exercise which not only simplify requirements explanations but also elicit new ones as well. 
The method can be adjusted so that it supports the product and the company strategy which makes it relevant for many different types of projects and companies. 
We can monitor the abstraction level of different stake holders and use the data for improvements. For example, one group of stake holders gives us requirements that are too abstract. 
Depending on the relevance of the stakeholders to the company and product strategy this could have different severity and meaning for our product. 
So by measuring the abstract we can see potential opportunities for improvements or change of strategy for the product. 

The method can contribute to too much rework of requirements and that can lead to an overwhelming amount of new requirements. 
This is something that the method can handle but also be the contributor to. This means that the users of this method need to take special care to this behaviour and be aware of the effect at all times. 
By my opinion this makes the method prone to human error behaviour.
 
The authors claim that RAM can be used and is relevant for all types of companies and projects. 
This is something that is true. But more compelling argument would be if RAM should be used, by whom should be used and why? 
What are the benefits of using this method if the company does not do market driven requirements engineering? 
Also what are the benefits if the company in question does not have large scale requirements engineering?

We can prioritise requirements similarly like the doctors prioritise patients[4]. Here the authors present a method for choosing requirements that would satisfy the needs of the product strategy. 
The method is called MERTS and has three main activities to follow. The activities are as follows:
1.	Early Requirements Triage.
2.	Requirements selection for release.
3.	Strategy rationale.

Basically the first step is a documentation and prioritisation method where the requirement is put in to perspective and assigned weights from 0-100. 
Then the requirements weights are compared with each other and selected as most fitting for the strategy. Then we can move to the second step which is make a product roadmap and estimate effort for it. 
And the last step is documenting the reasoning of why the product can succeed. 

This methodology is simple to follow and easy to adapt to most cases. This means that the method can be adapted for most cases and can be modified for the need of the user. 
Another positive is that the method is using grading system. This way we simplify the decision making and also closely follow the strategy that we have for our product.
 
There are some problems that I can see with this methodology as well. When we get large scale of requirements this method might produce requirements with same grade. 
And here we are faced with the problem of questioning was the grading done correctly. 
The grading and the answering of the questions that produce the grade can be dependent on the knowledge that the grader has of the product strategy and the functionality as well. 
Abstract requirements can also be misunderstood by the one grading them. Who is doing the grading and why? 

In order to get an in depth understanding of release planning we can use provotypeing as a method of conducting research [5]. 
In this article the author uses a tool in order to get better understandings of what are the needs of the release planning professionals.
He does that by creating a tool that will provide support for the basic needs for creating a release plan. 
Then by using the tool together with professionals he takes notes of what is needed and how the participants reacted to the tools features. 
By doing so he found out what was missing rather than if what was already there is good enough.

This paper shows many interesting arguments. The most interesting to me were the method used, the tool used, and the understanding of the problem. 
The method used allowed the author to question what is missing instead of what we have and how is it performing. 
By doing so some new features were deducted as missing. It also allowed the author to realise what were the needs of the users and how they differ with his own expectations. 
And this leads us to the tool and what betterments are needed in order for the tool to satisfy the needs of the user. One of those needs was more control over the outcome of the tool. 
The users felt like it was hard to make the tool produce the wanted result. This was due to misunderstanding of the intended use of the tool. Hence the understanding of the problem becomes clear. 
Release planning is not a problem with one simple solution instead with many different solutions. Each solution can be correct in the right circumstances and wrong in different. 
A tool can be used for giving different options but the human mind needs to decide which option is the right one for the given circumstances. 

Seminar 3
Obsolete software requirements are requirements that make it in the release planning but are not implemented because of various reasons[6]. Or as the author defined it: 
“An obsolete software requirement is a software requirement (implemented or not) that is no longer required for the current release or future releases and, 
for various reasons, has little or no business value for the potential customers or users of a software product.”

As the research suggest these type of requirements can have negative impact in different areas of a project. 
The method that is used to come to the results presented by the authors is a data collection by surveys of practitioners in the industry. 
The interviewees come with experience from different development methodologies.

In the article the connection between different perspectives that the participants of the survey had and their choices is presented clearly and in a way that is easy to relate. 
For an example one of the research questions had to do with the severity of the impact that obsolete requirements have on the project. Here the author makes good connection that is based on the data collected. 
The data showed that the developers and the managers had different opinion on the severity of the impact. 
Here the authors connection that the understanding of the severity that these type of requirements have on the project also depend on the size of the company, 
development methodology and if the company had a prepared method to take care of these kind of requirements.
 
Another interesting connection is made when the author is analysing the reasons that this phenomenon occurs. 
Based on the results all type of requirements are at risk to become obsolete. 
However, at the highest risk of becoming obsolete requirements are the ones that are ambiguous, inconsistent or misunderstand. 
Some of the requirements that are low risk to become obsolete are the ones that are related to legislation and law. 

There is one critique that I can come up with regarding the type of data that the author is collecting and presenting.  
The author collects data via surveys and the questions in the surveys are regarding specific problems. 
Then the author presents the collected data which is indication that the problems are occurring. 
Then the author goes on and presents reasoning based on academic articles on what could lead to these problems. 
So what I would like to know is what the professionals think on these matters as well. By doing so the author could have present where the academia and the industry don’t see eye to eye. 

Measuring the changes of scope can tell us where in projects and at what stage of projects we can be better[7]. 
In order to do so the authors of that article explain a method to measure and graphically present the measurements. 
The authors adapt the measurements accordingly to the specific case and requirements management methodology that the company uses. 
According to the authors we need to take in to consideration including and cancelation of requirements, at what time of the project lifetime these changes occur, and the reason for scope changes.

I agree with the authors about both arguments that are made in the article. 
Monitoring behaviour of the requirements during the project is a good idea. 
Based on this we could make educated guesses on amongst other the most wanted features, problematic areas, and the code that is most likely to be reused. 
These could lead to betterment of scope planning and project size estimation. Having graphical presentation could be used as evidence for planning projects similar to previous ones. 
The method presented in the article is not applicable for all situations. 
Hence what we measure and the way we measure might need to be changed based on the requirements management methodology that we use.
Which leads to the method being limiting in some contexts. This is not necessarily a bed thing because the idea can be adopted and modified for the need of the user.
What is important to show and how we present that graphically is also a subject of discussion but still the need to do so is clearly presented by the article.
 
Both articles [6] and [7] report on requirements becoming obsolete. Which is not so strange due to the nature of the requirement process. 
Some requirements need to be changed or become obsolete due to unforeseen circumstances. And we are left with two options either adapt to the needed change or ignore the change and accept the consequences. 
Knowing the possibilities and probabilities at which the need for change to occur can help us to plan a strategy on how to deal with them accordingly.

[1]	G. Ruhe and M. O. Saliu, “The art and science of software release planning,” IEEE Softw., vol. 22, no. 6, pp. 47–53, 2005.
[2]	T. Gorschek and A. M. Davis, “Requirements engineering: In search of the dependent variables,” Inf. Softw. Technol., vol. 50, no. 1–2, pp. 67–75, Jan. 2008.
[3]	T. Gorschek and C. Wohlin, “Requirements Abstraction Model,” Requir. Eng., vol. 11, no. 1, p. 79, 2006.
[4]	M. Khurum, K. Aslam, and T. Gorschek, “A Method for Early Requirements Triage and Selection Utilizing Product Strategies,” in 14th Asia-Pacific Software Engineering Conference (APSEC’07), 2007, pp. 97–104.
[5]	P. Carlshamre, “Release Planning in Market-Driven Software Product Development,” Requir. Eng., vol. 7, no. 3, p. 139, 2002.
[6]	K. Wnuk, T. Gorschek, and S. Zahda, “Obsolete Software Requirements,” Inf. Softw. Technol., vol. 55, no. 6, p. 921, 2013.
[7]	K. Wnuk, B. Regnell, and L. Karlsson, “What Happened to Our Features? Visualization and Understanding of Scope Change Dynamics in a Large-Scale Industrial Setting,” in 2009 17th IEEE International Requirements Engineering Conference, 2009, pp. 89–98.


